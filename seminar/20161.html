<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>2016秋季组会</title></head><body style="font-family: 'Open Sans', Helvetica, Arial, sans-serif;font-size: 15px;font-weight: 300;"><h1 style="text-align: center;">2016秋季组会</h1><div style="float: right;" ><nav style="font-size: 1.6rem;"><div style="position: fixed;top: 0;right:0;font-size: 0.75em;height: 100% ;background-color: rgba(235, 222, 180, 0.86);"><ul><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="http://114.55.145.9:2334/cgi-bin/seminar.py">Group Seminar</a></li><br><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-09-14">2016-09-14</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-09-24">2016-09-24</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-10-15">2016-10-15</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-10-22">2016-10-22</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-10-29">2016-10-29</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-11-06">2016-11-06</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-11-12">2016-11-12</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-11-19">2016-11-19</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-11-27">2016-11-27</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-12-03">2016-12-03</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-12-10">2016-12-10</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-12-17">2016-12-17</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-12-24">2016-12-24</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2016-12-31">2016-12-31</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2017-01-07">2017-01-07</a></li><li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#date2017-01-14">2017-01-14</a></li><br><br>
<li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="#top">Top<br><br></a></li>
<!---
<li style="margin-left: 0;"><a style="color: #196d92;padding-left: 1.5rem;padding-right: 1.5rem;" href="uploadserver.py">[Submit files]<br></a></li>
--->
</ul></div></nav></div><div style="left:10;width:80%"><section></section><section id="date2016-09-14" ><h3 ><hr>Date:2016-09-14<br></h3><b>Title: </b>Belief & Evidence in Empirical Software Engineering<br><b>Speaker: </b>周鸣鸣<br><b>Paper:</b>ICSE2016<a href="http://114.55.145.9:8080/References/seminar/ICSE2016/Belief & Evidence in Empirical Software Engineering.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">Empirical software engineering has produced a steady stream of evidence-based results concerning the factors that affect important outcomes such as cost, quality, and interval. However, programmers often also have strongly-held a priori opinions about these issues. These opinions are important, since developers are highly-trained professionals whose beliefs would doubtless affect their practice. As in evidence-based medicine, disseminating empirical findings to developers is a key step in ensuring that the findings impact practice. In this paper, we describe a case study, on the prior beliefs of developers at Microsoft, and the relationship of these beliefs to actual empirical data on the projects in which these developers work. Our findings are that a) programmers do indeed have very strong beliefs on certain topics b) their beliefs are primarily formed based on personal experience, rather than on findings in empirical research and c) beliefs can vary with each project, but do not necessarily correspond with actual evidence in that project. Our findings suggest that more effort should be taken to disseminate empirical findings to developers and that more in-depth study the interplay of belief and evidence in software practice is needed.
</div><br><b>Title: </b>Ranking Relevance in Yahoo Search<br><b>Speaker: </b>虞烨炜<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/Ranking Relevance in Yahoo Search.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">Search engines play a crucial role in our daily lives. Relevance is the core problem of a commercial search engine. It has attracted thousands of researchers from both academia and industry and has been studied for decades. Relevance in a modern search engine has gone far beyond text matching, and now involves tremendous challenges. The semantic gap between queries and URLs is the main barrier for improving base relevance. Clicks help provide hints to improve relevance, but unfortunately for most tail queries, the click information is too sparse, noisy, or missing entirely. For comprehensive relevance, the recency and location sensitivity of results is also critical.<br> In this paper, we give an overview of the solutions for relevance in the Yahoo search engine. We introduce three key techniques for base relevance–ranking functions, semantic matching features and query rewriting. We also describe solutions for recency sensitive relevance and location sensitive relevance. This work builds upon 20 years of existing efforts on Yahoo search, summarizes the most recent advances and provides a series of practical relevance solutions. The reported performance is based on Yahoo’s commercial search engine, where tens of billions of URLs are indexed and served by the ranking system.
</div><br><b>Title: </b>Equiangular Kernel Dictionary Learning with Applications to Dynamic Texture Analysis<br><b>Speaker: </b>方宾伟<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/Equiangular Kernel Dictionary Learning with Applications to Dynamic Texture Analysis.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">Most existing dictionary learning algorithms consider a linear sparse model, which often cannot effectively characterize the nonlinear properties present in many types of visual data, e.g. dynamic texture (DT). Such nonlinear properties can be exploited by the so-called kernel sparse coding. This paper proposed an equiangular kernel dictionary learning method with optimal mutual coherence to exploit the nonlinear sparsity of high-dimensional visual data. Two main issues are addressed in the proposed method: (1) coding stability for redundant dictionary of inﬁnite-dimensional space; and (2) computational efﬁciency for computing kernel matrix of training samples of high-dimensional data. The proposed kernel sparse coding method is applied to dynamic texture analysis with both local DT pattern extraction and global DT pattern characterization. The experimental results showed its performance gain over existing methods.
</div><br><b>Title: </b>DeepIntent Learning Attentions for Online Advertising<br><b>Speaker: </b>郑永立<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/DeepIntent Learning Attentions for Online Advertising.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">In this paper, we investigate the use of recurrent neural networks (RNNs) in the context of search-based online advertising. We use RNNs to map both queries and ads to real valued vectors, with which the relevance of a given (query, ad) pair can be easily computed. On top of the RNN, we propose a novel attention network, which learns to assign attention scores to different word locations according to their intent importance (hence the name DeepIntent). The vector output of a sequence is thus computed by a weighted sum of the hidden states of the RNN at each word according their attention scores. We perform end-to-end training of both the RNN and attention network under the guidance of user click logs, which are sampled from a commercial search engine. We show that in most cases the attention network improves the quality of learned vector representations, evaluated by AUC on a manually labeled dataset. Moreover, we highlight the effectiveness of the learned attention scores from two aspects: query rewriting and a modified BM25 metric. We show that using the learned attention scores, one is able to produce sub-queries that are of better qualities than those of the state-of-the-art methods. Also, by modifying the term frequency with the attention scores in a standard BM25 formula, one is able to improve its performance evaluated by AUC.
</div><br><b>Title: </b>Human Language Reveals a Universal Positivity Bias<br><b>Speaker: </b>李甫宪<br><b>Paper:</b>PNAS<a href="http://114.55.145.9:8080/References/seminar/PNAS/Human Language Reveals a Universal Positivity Bias.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">Using human evaluation of 100,000 words spread across 24 corpora in 10 languages diverse in origin and culture, we present evidence of a deep imprint of human sociality in language, observing that (i) the words of natural human language possess a universal positivity bias, (ii) the estimated emotional content of words is consistent between languages under translation, and (iii) this positivity bias is strongly independent of frequency of word use. Alongside these general regularities, we describe interlanguage variations in the emotional spectrum of languages that allow us to rank corpora. We also show how our word evaluations can be used to construct physical-like instruments for both real-time and offline measurement of the emotional content of large-scale texts.
</div><br></section><section id="date2016-09-24" ><h3 ><hr>Date:2016-09-24<br></h3><b>Title: </b>Taxi Driving Behavior Analysis in Latent Vehicle-to-Vehicle Networks A Social Influence Perspective<br><b>Speaker: </b>王金宝<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/Taxi Driving Behavior Analysis in Latent Vehicle-to-Vehicle Networks A Social Influence Perspective.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201609240.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">With recent advances in mobile and sensor technologies, a large amount of eﬀorts have been made on developing intelligent applications for taxi drivers, which provide beneﬁcial guide and opportunity to improve the proﬁt and work eﬃciency. However, limited scopes focus on the latent social interaction within cab drivers, and corresponding social propagation scheme to share driving behaviors has been largely ignored. To that end, in this paper, we propose a comprehensive study to reveal how the social propagation aﬀects for better prediction of cab drivers’ future behaviors. To be speciﬁc, we ﬁrst investigate the correlation between drivers’ skills and their mutual interactions in the latent vehicleto-vehicle network, which intuitively indicates the eﬀects of social inﬂuences. Along this line, by leveraging the classic social inﬂuence theory, we develop a two-stage framework for quantitatively revealing the latent driving pattern propagation within taxi drivers. Comprehensive experiments on a real-word data set collected from the New York City clearly validate the eﬀectiveness of our proposed framework on predicting future taxi driving behaviors, which also support the hypothesis that social factors indeed improve the predictability of driving behaviors.
</div><br><b>Title: </b>Overcoming Open Source Project Entry Barriers with a Portal for Newcomers<br><b>Speaker: </b>朱天潼<br><b>Paper:</b>ICSE2016<a href="http://114.55.145.9:8080/References/seminar/ICSE2016/Overcoming Open Source Project Entry Barriers with a Portal for Newcomers.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201609241.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Community-based Open Source Software (OSS) projects are usually self-organized and dynamic, receiving contributions from distributed volunteers. Newcomer are important to the survival, long-term success, and continuity of these communities. However, newcomers face many barriers when making their first contribution to an OSS project, leading in many cases to dropouts. Therefore, a major challenge for OSS projects is to provide ways to support newcomers during their first contribution. In this paper, we propose and evaluate FLOSScoach, a portal created to support newcomers to OSS projects. FLOSScoach was designed based on a conceptual model of barriers created in our previous work. To evaluate the portal, we conducted a study with 65 students, relying on qualitative data from diaries, self-efficacy questionnaires, and the Technology Acceptance Model. The results indicate that FLOSScoach played an important role in guiding newcomers and in lowering barriers related to the orientation and contribution process, whereas it was not effective in lowering technical barriers. We also found that FLOSScoach is useful, easy to use, and increased newcomers’ confidence to contribute. Our results can help project maintainers on deciding the points that need more attention in order to help OSS project newcomers overcome entry barriers.
</div><br><b>Title: </b>Picking Deep Filter Responses for Fine-grained Image Recognition<br><b>Speaker: </b>肖浩泉<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/Picking Deep Filter Responses for Fine-grained Image Recognition.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201609242.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Recognizing ﬁne-grained sub-categories such as birds and dogs is extremely challenging due to the highly localized and subtle diﬀerences in some speciﬁc parts. Most previous works rely on object/part level annotations to build part-based representation, which is demanding in practical applications. This paper proposes an automatic ﬁnegrained recognition approach which is free of any object/part annotation at both training and testing stages. Our method explores a uniﬁed framework based on two steps of deep ﬁlter response picking. The ﬁrst picking step is to ﬁnd distinctive ﬁlters which respond to speciﬁc patterns signiﬁcantly and consistently, and learn a set of part detectors via iteratively alternating between new positive sample mining and part model retraining. The second picking step is to pool deep ﬁlter responses via spatially weighted combination of Fisher Vectors. We conditionally pick deep ﬁlter responses to encode them into the ﬁnal representation, which considers the importance of ﬁlter responses themselves. Integrating all these techniques produces a much more powerful framework, and experiments conducted on CUB-2002011 and Stanford Dogs demonstrate the superiority of our proposed algorithm over the existing methods.
</div><br><b>Title: </b>Detecting events and key actors in multi-person videos<br><b>Speaker: </b>方宾伟<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/Detecting events and key actors in multi-person videos.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201609243.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Multi-person event recognition is a challenging task, often with many people active in the scene but only a small subset contributing to an actual event. In this paper, we propose a model which learns to detect events in such videos while automatically “attending” to the people responsible for the event. Our model does not use explicit annotations regarding who or where those people are during training and testing. In particular, we track people in videos and use a recurrent neural network (RNN) to represent the track features. We learn time-varying attention weights to combine these features at each time-instant. The attended features are then processed using another RNN for event detection/classification. Since most video datasets with multiple people are restricted to a small number of videos, we also collected a new basketball dataset comprising 257 basketball games with 14K event annotations corresponding to 11 event classes. Our model outperforms state-of-the-art methods for both event classification and detection on this new dataset. Additionally, we show that the attention mechanism is able to consistently localize the relevant players.
</div><br></section><section id="date2016-10-15" ><h3 ><hr>Date:2016-10-15<br></h3><b>Title: </b>DeepFashion Powering Robust Clothes Recognition and Retrieval with rich annotations<br><b>Speaker: </b>李甫宪<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/DeepFashion Powering Robust Clothes Recognition and Retrieval with rich annotations.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610150.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Recent advances in clothes recognition have been driven by the construction of clothes datasets. Existing datasets are limited in the amount of annotations and are diffi-cult to cope with the various challenges in real-world applications. In this work, we introduce DeepFashion1 , a large-scale clothes dataset with comprehensive annotations. It contains over 800,000 images, which are richly annotated with massive attributes, clothing landmarks, and correspondence of images taken under different scenarios including store, street snapshot, and consumer. Such rich annotations enable the development of powerful algorithms in clothes recognition and facilitating future researches. To demonstrate the advantages of DeepFashion, we propose a new deep model, namely FashionNet, which learns clothing features by jointly predicting clothing attributes and landmarks. The estimated landmarks are then employed to pool or gate the learned features. It is optimized in an iterative manner. Extensive experiments demonstrate the effectiveness of FashionNet and the usefulness of DeepFashion.
</div><br><b>Title: </b>When do Recommender Systems Work the Best<br><b>Speaker: </b>樊坤鹏<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/When do Recommender Systems Work the Best.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610151.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">We investigate the moderating effect of product attributes and consumer reviews on the efficacy of a collaborative filtering recommender system on an e-commerce site. We run a randomized field experiment on a top North American retailer’s website with 184,375 users split into a recommendertreated group and a control group with 37,215 unique products in the dataset. By augmenting the dataset with Amazon Mechanical Turk tagged product attributes and consumer review data from the website, we study their moderating influence on recommenders in generating conversion. We first confirm that the use of recommenders increases the baseline conversion rate by 5.9%. We find that the recommenders act as substitutes for high average review ratings with the effect of using recommenders increasing the conversion rate as much as about 1.4 additional average star ratings. Additionally, we find that the positive impacts on conversion from recommenders are greater for hedonic products compared to utilitarian products while searchexperience quality did not have any impact. We also find that the higher the price, the lower the positive impact of recommenders, while having lengthier product descriptions and higher review volumes increased the recommender’s effectiveness. More findings are discussed in the Results. For managers, we 1) identify the products and product attributes for which the recommenders work well, 2) show how other product information sources on e-commerce sites interact with recommenders. Additionally, the insights from the results could inform novel recommender algorithm designs that are aware of strength and shortcomings. From an academic standpoint, we provide insight into the underlying mechanism behind how recommenders cause consumers to purchase. 
</div><br><b>Title: </b>node2vec Scalable Feature Learning for Networks<br><b>Speaker: </b>赵明浩<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/node2vec Scalable Feature Learning for Networks.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610152.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node’s network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-ofthe-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning stateof-the-art task-independent representations in complex networks.
</div><br><b>Title: </b>Women’s connectivity in extreme networks<br><b>Speaker: </b>虞烨炜<br><b>Paper:</b>Science<a href="http://114.55.145.9:8080/References/seminar/Science/Women’s connectivity in extreme networks.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610153.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">A popular stereotype is that women will play more minor roles than men as environments become more dangerous and aggressive. Our analysis of new longitudinal data sets from offline and online operational networks [for example, ISIS (Islamic State)] shows that although men dominate numerically, women emerge with superior network connectivity that can benefit the underlying system’s robustness and survival. Our observations suggest new female-centric approaches that could be used to affect such networks. They also raise questions about how individual contributions in high-pressure systems are evaluated.
</div><br><b>Title: </b>Modeling User Consumption Sequences<br><b>Speaker: </b>Paul<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/Modeling User Consumption Sequences.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610154.ppt">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">We study sequences of consumption in which the same item may be consumed multiple times. We identify two macroscopic behavior patterns of repeated consumptions. First, in a given user’s lifetime, very few items live for a long time. Second, the last consumptions of an item exhibit growing inter-arrival gaps consistent with the notion of increasing boredom leading up to eventual abandonment. We then present what is to our knowledge the first holistic model of sequential repeated consumption, covering all observed aspects of this behavior. Our simple and purely combinatorial model includes no planted notion of lifetime distributions or user boredom; nonetheless, the model correctly predicts both of these phenomena. Further, we provide theoretical analysis of the behavior of the model confirming these phenomena. Additionally, the model quantitatively matches a number of microscopic phenomena across a broad range of datasets. Intriguingly, these findings suggest that the observation in a variety of domains of increasing user boredom leading to abandonment may be explained simply by probabilistic conditioning on an extinction event in a simple model, without resort to explanations based on complex human dynamics.
</div><br><b>Title: </b>Social Networks Under Stress<br><b>Speaker: </b>姜磊<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/Social Networks Under Stress.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610155.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Social network research has begun to take advantage of finegrained communications regarding coordination, decisionmaking, and knowledge sharing. These studies, however, have not generally analyzed how external events are associated with a social network’s structure and communicative properties. Here, we study how external events are associated with a network’s change in structure and communications. Analyzing a complete dataset of millions of instant messages among the decision-makers in a large hedge fund and their network of outside contacts, we investigate the link between price shocks, network structure, and change in the affect and cognition of decision-makers embedded in the network. When price shocks occur the communication network tends not to display structural changes associated with adaptiveness. Rather, the network “turtles up”. It displays a propensity for higher clustering, strong tie interaction, and an intensification of insider vs. outsider communication. Further, we find changes in network structure predict shifts in cognitive and affective processes, execution of new transactions, and local optimality of transactions better than prices, revealing the important predictive relationship between network structure and collective behavior within a social network.
</div><br><b>Title: </b>Video Segmentation via Object Flow<br><b>Speaker: </b>方宾伟<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/Video Segmentation via Object Flow.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610156.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Video object segmentation is challenging due to fast moving objects, deforming shapes, and cluttered backgrounds. Optical flow can be used to propagate an object segmentation over time but, unfortunately, flow is often inaccurate, particularly around object boundaries. Such boundaries are precisely where we want our segmentation to be accurate. To obtain accurate segmentation across time, we propose an efficient algorithm that considers video segmentation and optical flow estimation simultaneously. For video segmentation, we formulate a principled, multiscale, spatio-temporal objective function that uses optical flow to propagate information between frames. For optical flow estimation, particularly at object boundaries, we compute the flow independently in the segmented regions and recompose the results. We call the process object flow and demonstrate the effectiveness of jointly optimizing optical flow and video segmentation using an iterative scheme. Experiments on the SegTrack v2 and YoutubeObjects datasets show that the proposed algorithm performs favorably against the other state-of-the-art methods.
</div><br><b>Title: </b>Revisiting Code Ownership and its Relationship with Software Quality in the Scope of Modern Code Review<br><b>Speaker: </b>周鸣鸣<br><b>Paper:</b>ICSE2016<a href="http://114.55.145.9:8080/References/seminar/ICSE2016/Revisiting Code Ownership and its Relationship with Software Quality in the Scope of Modern Code Review.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610157.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Code ownership establishes a chain of responsibility for modules in large software systems. Although prior work uncovers a link between code ownership heuristics and software quality, these heuristics rely solely on the authorship of code changes. In addition to authoring code changes, developers also make important contributions to a module by reviewing code changes. Indeed, recent work shows that reviewers are highly active in modern code review processes, often suggesting alternative solutions or providing updates to the code changes. In this paper, we complement traditional code ownership heuristics using code review activity. Through a case study of six releases of the large Qt and OpenStack systems, we find that: (1) 67%-86% of developers did not author any code changes for a module, but still actively contributed by reviewing 21%-39% of the code changes, (2) code ownership heuristics that are aware of reviewing activity share a relationship with software quality, and (3) the proportion of reviewers without expertise shares a strong, increasing relationship with the likelihood of having post-release defects. Our results suggest that reviewing activity captures an important aspect of code ownership, and should be included in approximations of it in future studies.
</div><br><b>Title: </b>Beyond Collaborative Filtering The List Recommendation Problem<br><b>Speaker: </b>靳继伟<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/Beyond Collaborative Filtering The List Recommendation Problem.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610158.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Most Collaborative Filtering (CF) algorithms are optimized using a dataset of isolated user-item tuples. However, in commercial applications recommended items are usually served as an ordered list of several items and not as isolated items. In this setting, inter-item interactions have an effect on the list’s Click-Through Rate (CTR) that is unaccounted for using traditional CF approaches. Most CF approaches also ignore additional important factors like click propensity variation, item fatigue, etc. In this work, we introduce the list recommendation problem. We present useful insights gleaned from user behavior and consumption patterns from a large scale real world recommender system. We then propose a novel two-layered framework that builds upon existing CF algorithms to optimize a list’s click probability. Our approach accounts for inter-item interactions as well as additional information such as item fatigue, trendiness patterns, contextual information etc. Finally, we evaluate our approach using a novel adaptation of Inverse Propensity Scoring (IPS) which facilitates off-policy estimation of our method’s CTR and showcases its effectiveness in real-world settings.
</div><br></section><section id="date2016-10-22" ><h3 ><hr>Date:2016-10-22<br></h3><b>Title: </b>Gender Productivity and Prestige in Computer Science Faculty Hiring Networks<br><b>Speaker: </b>靳继伟<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/Gender%20Productivity%20and%20Prestige%20in%20Computer%20Science%20Faculty%20Hiring%20Networks.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610220.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Women are dramatically underrepresented in computer science at all levels in academia and account for just 15% of tenure-track faculty. Understanding the causes of this gender imbalance would inform both policies intended to rectify it and employment decisions by departments and individuals. Progress in this direction, however, is complicated by the complexity and decentralized nature of faculty hiring and the non-independence of hires. Using comprehensive data on both hiring outcomes and scholarly productivity for 2659 tenure-track faculty across 205 Ph.D.-granting departments in North America, we investigate the multidimensional nature of gender inequality in computer science faculty hiring through a network model of the hiring process. Overall, we find that hiring outcomes are most directly affected by the relative prestige between hiring and placing institutions and the scholarly productivity of the candidates. After including these, and other features, the addition of gender did not significantly reduce modeling error. However, gender differences do exist, e.g., in scholarly productivity, postdoctoral training rates, and in career movements up the rankings of universities, suggesting that the effects of gender are indirectly incorporated into hiring decisions through gender’s covariates. Furthermore, we find evidence that more highly ranked departments recruit female faculty at higher than expected rates, which appears to inhibit similar efforts by lower ranked departments. These findings illustrate the subtle nature of gender inequality in faculty hiring networks and provide new insights to the underrepresentation of women in computer science.</div><br><b>Title: </b>When Social Influence Meets Item Inference<br><b>Speaker: </b>虞烨炜<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/When Social Influence Meets Item Inference.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610221.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Research issues and data mining techniques for product recommendation and viral marketing have been widely studied. Existing works on seed selection in social networks do not take into account the effect of product recommendations in e-commerce stores. In this paper, we investigate the seed selection problem for viral marketing that considers both effects of social influence and item inference (for product recommendation). We develop a new model, Social Item Graph (SIG), that captures both effects in the form of hyperedges. Accordingly, we formulate a seed selection problem, called Social Item Maximization Problem (SIMP), and prove the hardness of SIMP. We design an efficient algorithm with performance guarantee, called Hyperedge-Aware Greedy (HAG), for SIMP and develop a new index structure, called SIG-index, to accelerate the computation of diffusion process in HAG. Moreover, to construct realistic SIG models for SIMP, we develop a statistical inference based framework to learn the weights of hyperedges from data. Finally, we perform a comprehensive evaluation on our proposals with various baselines. Experimental result validates our ideas and demonstrates the effectiveness and efficiency of the proposed model and algorithms over baselines.
</div><br><b>Title: </b>Large-Scale Item Categorization in e-Commerce Using Multiple Recurrent Neural Networks<br><b>Speaker: </b>郑永立<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/Large-Scale Item Categorization in e-Commerce Using Multiple Recurrent Neural Networks.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610222.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Precise item categorization is a key issue in e-commerce domains. However, it still remains a challenging problem due to data size, category skewness, and noisy metadata. Here, we demonstrate a successful report on a deep learning-based item categorization method, i.e., deep categorization network (DeepCN), in an ecommerce website. DeepCN is an end-to-end model using multiple recurrent neural networks (RNNs) dedicated to metadata attributes for generating features from text metadata and fully connected layers for classifying item categories from the generated features. The categorization errors are propagated back through the fully connected layers to the RNNs for weight update in the learning process. This deep learning-based approach allows diverse attributes to be integrated into a common representation, thus overcoming sparsity and scalability problems. We evaluate DeepCN on large-scale real-world data including more than 94 million items with approximately 4,100 leaf categories from a Korean e-commerce website. Experiment results show our method improves the categorization accuracy compared to the model using single RNN as well as a standard classification model using unigram-based bag-of-words. Furthermore, we investigate how much the model parameters and the used attributes influence categorization performances.
</div><br><b>Title: </b>SketchNet:Sketch Classification with Web Images<br><b>Speaker: </b>肖浩泉<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/SketchNet:Sketch Classification with Web Images.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610223.ppt">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">In this study, we present a weakly supervised approach that discovers the discriminative structures of sketch images, given pairs of sketch images and web images. In contrast to traditional approaches that use global appearance features or relay on keypoint features, our aim is to automatically learn the shared latent structures that exist between sketch images and real images, even when there are significant appearance differences across its relevant real images. To accomplish this, we propose a deep convolutional neural network, named SketchNet. We firstly develop a triplet composed of sketch, positive and negative real image as the input of our neural network. To discover the coherent visual structures between the sketch and its positive pairs, we introduce the softmax as the loss function. Then a ranking mechanism is introduced to make the positive pairs obtain a higher score comparing over negative ones to achieve robust representation. Finally, we formalize above-mentioned constrains into the unified objective function, and create an ensemble feature representation to describe the sketch images. Experiments on the TUBerlin sketch benchmark demonstrate the effectiveness of our model and show that deep feature representation brings substantial improvements over other state-of-the-art methods on sketch classification.
</div><br><b>Title: </b>Code Review Quality How Developers See It<br><b>Speaker: </b>朱天潼<br><b>Paper:</b>ICSE2016<a href="http://114.55.145.9:8080/References/seminar/ICSE2016/Code Review Quality How Developers See It.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610224.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">In a large, long-lived project, an effective code review process is key to ensuring the long-term quality of the code base. In this work, we study code review practices of a large, open source project, and we investigate how the developers themselves perceive code review quality. We present a qualitative study that summarizes the results from a survey of 88 Mozilla core developers. The results provide developer insights into how they define review quality, what factors contribute to how they evaluate submitted code, and what challenges they face when performing review tasks. We found that the review quality is primarily associated with the thoroughness of the feedback, the reviewer’s familiarity with the code, and the perceived quality of the code itself. Also, we found that while different factors are perceived to contribute to the review quality, reviewers often find it difficult to keep their technical skills up-to-date, manage personal priorities, and mitigate context switching.
</div><br><b>Title: </b>Cross-evaluation of metrics to estimate the significance of creative works<br><b>Speaker: </b>赵明浩<br><b>Paper:</b>PNAS<a href="http://114.55.145.9:8080/References/seminar/PNAS/Cross-evaluation of metrics to estimate the significance of creative works.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610225.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">In a world overflowing with creative works, it is useful to be able to filter out the unimportant works so that the significant ones can be identified and thereby absorbed. An automated method could provide an objective approach for evaluating the significance of works on a universal scale. However, there have been few attempts at creating such a measure, and there are few “ground truths” for validating the effectiveness of potential metrics for significance. For movies, the US Library of Congress’s National Film Registry (NFR) contains American films that are “culturally, historically, or aesthetically significant” as chosen through a careful evaluation and deliberation process. By analyzing a network of citations between 15,425 United States-produced films procured from the Internet Movie Database (IMDb), we obtain several automated metrics for significance. The best of these metrics is able to indicate a film’s presence in the NFR at least as well or better than metrics based on aggregated expert opinions or large population surveys. Importantly, automated metrics can easily be applied to older films for which no other rating may be available. Our results may have implications for the evaluation of other creative works such as scientific research.
</div><br></section><section id="date2016-10-29" ><h3 ><hr>Date:2016-10-29<br></h3><b>Title: </b>What links Alice and Bob ? Matching and Ranking Semantic Patterns in Heterogeneous Networks<br><b>Speaker: </b>王金宝<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/What links Alice and Bob ? Matching and Ranking Semantic Patterns in Heterogeneous Networks.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610290.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">An increasing number of applications are modeled and analyzed in network form, where nodes represent entities of interest and edges represent interactions or relationships between entities. Commonly, such relationship analysis tools assume homogeneity in both node type and edge type. Recent research has sought to redress the assumption of homogeneity and focused on mining heterogeneous information networks (HINs) where both nodes and edges can be of different types. Building on such efforts, in this work we articulate a novel approach for mining relationships across entities in such networks while accounting for user preference over relationship type and interestingness metric. We formalize the problem as a top-k lightest paths problem, contextualized in a real-world communication network, and seek to find the k most interesting path instances matching the preferred relationship type. Our solution, PROphetic HEuristic Algorithm for Path Searching (PRO-HEAPS), leverages a combination of novel graph preprocessing techniques, well designed heuristics and the venerable A* search algorithm. We run our algorithm on real-world large-scale graphs and show that our algorithm significantly outperforms a wide variety of baseline approaches with speedups as large as 100X. We also conduct a case study and demonstrate valuable applications of our algorithm.
</div><br><b>Title: </b>Stacked Attention Networks for Image Question Answering<br><b>Speaker: </b>李甫宪<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/Stacked Attention Networks for Image Question Answering.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610291.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">This paper presents stacked attention networks (SANs) that learn to answer natural language questions from images. SANs use semantic representation of a question as query to search for the regions in an image that are related to the answer. We argue that image question answering (QA) often requires multiple steps of reasoning. Thus, we develop a multiple-layer SAN in which we query an image multiple times to infer the answer progressively. Experiments conducted on four image QA data sets demonstrate that the proposed SANs significantly outperform previous state-of-the-art approaches. The visualization of the attention layers illustrates the progress that the SAN locates the relevant visual clues that lead to the answer of the question layer-by-layer.
</div><br><b>Title: </b>Generation and Comprehension of Unambiguous Object Descriptions<br><b>Speaker: </b>方宾伟<br><b>Paper:</b>Arxiv<a href="http://114.55.145.9:8080/References/seminar/Arxiv/Generation and Comprehension of Unambiguous Object Descriptions.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201610292.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">We propose a method that can generate an unambiguous description (known as a referring expression) of a specific object or region in an image, and which can also comprehend or interpret such an expression to infer which object is being described. We show that our method outperforms previous methods that generate descriptions of objects without taking into account other potentially ambiguous objects in the scene. Our model is inspired by recent successes of deep learning methods for image captioning, but while image captioning is difficult to evaluate, our task allows for easy objective evaluation. We also present a new large-scale dataset for referring expressions, based on MSCOCO. We have released the dataset and a toolbox for visualization and evaluation, see https://github.com/ mjhucla/Google_Refexp_toolbox.
</div><br></section><section id="date2016-11-06" ><h3 ><hr>Date:2016-11-06<br></h3><b>Title: </b>GMove Group-Level Mobility Modeling Using Geo-Tagged Social Media<br><b>Speaker: </b>赵明浩<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/GMove%20Group-Level%20Mobility%20Modeling%20Using%20Geo-Tagged%20Social%20Media.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611060.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Understanding human mobility is of great importance to various applications, such as urban planning, traffic scheduling, and location prediction. While there has been fruitful research on modeling human mobility using tracking data (e.g., GPS traces), the recent growth of geo-tagged social media (GeoSM) brings new opportunities to this task because of its sheer size and multi-dimensional nature. Nevertheless, how to obtain quality mobility models from the highly sparse and complex GeoSM data remains a challenge that cannot be readily addressed by existing techniques. We propose GMOVE, a group-level mobility modeling method using GeoSM data. Our insight is that the GeoSM data usually contains multiple user groups, where the users within the same group share significant movement regularity. Meanwhile, user grouping and mobility modeling are two intertwined tasks: (1) better user grouping offers better within-group data consistency and thus leads to more reliable mobility models; and (2) better mobility models serve as useful guidance that helps infer the group a user belongs to. GMOVE thus alternates between user grouping and mobility modeling, and generates an ensemble of Hidden Markov Models (HMMs) to characterize group-level movement regularity. Furthermore, to reduce text sparsity of GeoSM data, GMOVE also features a text augmenter. The augmenter computes keyword correlations by examining their spatiotemporal distributions. With such correlations as auxiliary knowledge, it performs sampling-based augmentation to alleviate text sparsity and produce high-quality HMMs. Our extensive experiments on two real-life data sets demonstrate that GMOVE can effectively generate meaningful group-level mobility models. Moreover, with context-aware location prediction as an example application, we find that GMOVE significantly outperforms baseline mobility models in terms of prediction accuracy.</div><br><b>Title: </b>The Lifecycle and Cascade of WeChat Social Messaging Groups<br><b>Speaker: </b>靳继伟<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/The%20Lifecycle%20and%20Cascade%20of%20WeChat%20Social%20Messaging%20Groups.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611061.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Social instant messaging services are emerging as a transformative form with which people connect, communicate with friends in their daily life — they catalyze the formation of social groups, and they bring people stronger sense of community and connection. However, research community still knows little about the formation and evolution of groups in the context of social messaging — their lifecycles, the change in their underlying structures over time, and the diffusion processes by which they develop new members. In this paper, we analyze the daily usage logs from WeChat group messaging platform — the largest standalone messaging communication service in China — with the goal of understanding the processes by which social messaging groups come together, grow new members, and evolve over time. Specifically, we discover a strong dichotomy among groups in terms of their lifecycle, and develop a separability model by taking into account a broad range of group-level features, showing that long-term and shortterm groups are inherently distinct. We also found that the lifecycle of messaging groups is largely dependent on their social roles and functions in users’ daily social experiences and specific purposes. Given the strong separability between the long-term and short-term groups, we further address the problem concerning the early prediction of successful communities. In addition to modeling the growth and evolution from grouplevel perspective, we investigate the individual-level attributes of group members and study the diffusion process by which groups gain new members. By considering members’ historical engagement behavior as well as the local social network structure that they embedded in, we develop a membership cascade model and demonstrate the effectiveness by achieving AUC of 95.31% in predicting inviter, and an AUC of 98.66% in predicting invitee.</div><br><b>Title: </b>Ups and Downs : Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering<br><b>Speaker: </b>Paul<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/Ups%20and%20Downs%20Modeling%20the%20Visual%20Evolution%20of%20Fashion%20Trends%20with%20One-Class%20Collaborative%20Filtering.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611062.ppt">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Building a successful recommender system depends on understanding both the dimensions of people’s preferences as well as their dynamics. In certain domains, such as fashion, modeling such preferences can be incredibly difficult, due to the need to simultaneously model the visual appearance of products as well as their evolution over time. The subtle semantics and non-linear dynamics of fashion evolution raise unique challenges especially considering the sparsity and large scale of the underlying datasets. In this paper we build novel models for the One-Class Collaborative Filtering setting, where our goal is to estimate users’ fashion-aware personalized ranking functions based on their past feedback. To uncover the complex and evolving visual factors that people consider when evaluating products, our method combines high-level visual features extracted from a deep convolutional neural network, users’ past feedback, as well as evolving trends within the community. Experimentally we evaluate our method on two large real-world datasets from Amazon.com, where we show it to outperform stateof-the-art personalized ranking measures, and also use it to visualize the high-level fashion trends across the 11-year span of our dataset.</div><br><b>Title: </b>Recommendations in Signed Social Networks<br><b>Speaker: </b>姜磊<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/Recommendations%20in%20Signed%20Social%20Networks.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611063.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Recommender systems play a crucial role in mitigating the information overload problem in social media by suggesting relevant information to users. The popularity of pervasively available social activities for social media users has encouraged a large body of literature on exploiting social networks for recommendation. The vast majority of these systems focus on unsigned social networks (or social networks with only positive links), while little work exists for signed social networks (or social networks with positive and negative links). The availability of negative links in signed social networks presents both challenges and opportunities in the recommendation process. We provide a principled and mathematical approach to exploit signed social networks for recommendation, and propose a model, RecSSN, to leverage positive and negative links in signed social networks. Empirical results on real-world datasets demonstrate the effectiveness of the proposed framework. We also perform further experiments to explicitly understand the effect of signed networks in RecSSN.</div><br><b>Title: </b>From a Scholarly Big Dataset to a Test Collection for Bibliographic Citation Recommendation<br><b>Speaker: </b>樊坤鹏<br><b>Paper:</b>AAAI2016<a href="http://114.55.145.9:8080/References/seminar/AAAI2016/From%20a%20Scholarly%20Big%20Dataset%20to%20a%20Test%20Collection%20for%20Bibliographic%20Citation%20Recommendation.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611064.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">The problem of designing recommender systems for scholarly article citations has been actively researched with more than 200 publications appearing in the last two decades. In spite of this, no definitive results are available about what approaches work best. Arguably the most important reason for this lack of consensus is the dearth of standardised test collections and evaluation protocols, such as those provided by TREC-like forums. CiteSeerx , a “scholarly big dataset” has recently become available. However, this collection provides only the raw material that is yet to be moulded into Cranfield style test collections. In this paper, we discuss the limitations of test collections used in earlier work, and describe how we used CiteSeerx to design a test collection with a well-defined evaluation protocol. The collection consists of over 600,000 research papers and over 2,500 queries. We report some preliminary experimental results using this collection, which are indicative of the performance of elementary content-based techniques. These experiments also made us aware of some shortcomings of CiteSeerx itself.</div><br></section><section id="date2016-11-12" ><h3 ><hr>Date:2016-11-12<br></h3><b>Title: </b>The Challenges of Staying Together While Moving Fast An Exploratory Study<br><b>Speaker: </b>周鸣鸣<br><b>Paper:</b>ICSE2016<a href="http://114.55.145.9:8080/References/seminar/ICSE2016/The%20Challenges%20of%20Staying%20Together%20While%20Moving%20Fast%20An%20Exploratory%20Study.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611120.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">We report on the results of an empirical study conducted with 35 experienced software developers from 22 high-tech companies, including Google, Facebook, Microsoft, Intel, and others. The goal of the study was to elicit challenges that these developers face, potential solutions that they envision to these challenges, and research initiatives that they think would deliver useful results. Challenges identified by the majority of the study participants relate to the collaborative nature of the work: the availability and discoverability of information, communication, collaborative planning and integration with work of others. Almost all participants also addressed the advantages and disadvantages of the current “fast to the market” trend, and the toll it takes on the quality of the software that they are able to deliver and on their professional and personal satisfaction as software engineers. We describe in depth the identified challenges, supporting our findings with explicit quotes from the study participants. We also put these findings in context of work done by the software engineering community and outline a roadmap for possible future research initiatives.</div><br><b>Title: </b>Exploiting Dining Preference for Restaurant Recommendation<br><b>Speaker: </b>虞烨炜<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/Exploiting%20Dining%20Preference%20for%20Restaurant%20Recommendation.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611121.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">The wide adoption of location-based services provide the potential to understand people’s mobility pattern at an unprecedented level, which can also enable food-service industry to accurately predict consumers’ dining behavior. In this paper, based on users’ dining implicit feedbacks (restaurant visit via check-ins), explicit feedbacks (restaurant reviews) as well as some meta data (e.g., location, user demographics, restaurant attributes), we aim at recommending each user a list of restaurants for his next dining. Implicit and Explicit feedbacks of dining behavior exhibit different characteristics of user preference. Therefore, in our work, user’s dining preference mainly contains two parts: implicit preference coming from check-in data (implicit feedbacks) and explicit preference coming from rating and review data (explicit feedbacks). For implicit preference, we first apply a probabilistic tensor factorization model (PTF) to capture preference in a latent subspace. Then, in order to incorporate contextual signals from meta data, we extend PTF by proposing an Implicit Preference Model (IPM), which can simultaneously capture users’/restaurants’/time’ preference in the collaborative filtering and dining preference in a specific context (e.g., spatial distance preference, environmental preference). For explicit preference, we propose Explicit Preference Model (EPM) by combining matrix factorization with topic modeling to discover the user preference embedded both in rating score and text content. Finally, we design a unified model termed as Collective Implicit Explicit Preference Model (CIEPM) to combine implicit and explicit preference together for restaurant recommendation. To evaluate the performance of our system, we conduct extensive experiments with large-scale datasets covering hundreds of thousands of users and restaurants. The results reveal that our system is effective for restaurant recommendation.</div><br><b>Title: </b>Mining Subgroups with Exceptional Transition Behavior<br><b>Speaker: </b>郑永立<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/Mining%20Subgroups%20with%20Exceptional%20Transition%20Behavior.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611122.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">We present a new method for detecting interpretable subgroups with exceptional transition behavior in sequential data. Identifying such patterns has many potential applications, e.g., for studying human mobility or analyzing the behavior of internet users. To tackle this task, we employ exceptional model mining, which is a general approach for identifying interpretable data subsets that exhibit unusual interactions between a set of target attributes with respect to a certain model class. Although exceptional model mining provides a well-suited framework for our problem, previously investigated model classes cannot capture transition behavior. To that end, we introduce first-order Markov chains as a novel model class for exceptional model mining and present a new interestingness measure that quantifies the exceptionality of transition subgroups. The measure compares the distance between the Markov transition matrix of a subgroup and the respective matrix of the entire data with the distance of random dataset samples. In addition, our method can be adapted to find subgroups that match or contradict given transition hypotheses. We demonstrate that our method is consistently able to recover subgroups with exceptional transition models from synthetic data and illustrate its potential in two application examples. Our work is relevant for researchers and practitioners interested in detecting exceptional transition behavior in sequential data.</div><br><b>Title: </b>Mining Online Social Data for Detecting Social Network Mental Disorders<br><b>Speaker: </b>姜磊<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/Mining%20Online%20Social%20Data%20for%20Detecting%20Social%20Network%20Mental%20Disorders.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611123.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">An increasing number of social network mental disorders (SNMDs), such as Cyber-Relationship Addiction, Information Overload, and Net Compulsion, have been recently noted. Symptoms of these mental disorders are usually observed passively today, resulting in delayed clinical intervention. In this paper, we argue that mining online social behavior provides an opportunity to actively identify SNMDs at an early stage. It is challenging to detect SNMDs because the mental factors considered in standard diagnostic criteria (questionnaire) cannot be observed from online social activity logs. Our approach, new and innovative to the practice of SNMD detection, does not rely on self-revealing of those mental factors via questionnaires. Instead, we propose a machine learning framework, namely, Social Network Mental Disorder Detection (SNMDD), that exploits features extracted from social network data to accurately identify potential cases of SNMDs. We also exploit multi-source learning in SNMDD and propose a new SNMDbased Tensor Model (STM) to improve the performance. Our framework is evaluated via a user study with 3126 online social network users. We conduct a feature analysis, and also apply SNMDD on large-scale datasets and analyze the characteristics of the three SNMD types. The results show that SNMDD is promising for identifying online social network users with potential SNMDs.</div><br></section><section id="date2016-11-19" ><h3 ><hr>Date:2016-11-19<br></h3><b>Title: </b>Using Shortlists to Support Decision Making and Improve Recommender System Performance<br><b>Speaker: </b>靳继伟<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/Using Shortlists to Support Decision Making and Improve Recommender System Performance.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611190.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">In this paper, we study shortlists as an interface component for recommender systems with the dual goal of supporting the user’s decision process, as well as improving implicit feedback elicitation for increased recommendation quality. A shortlist is a temporary list of candidates that the user is currently considering, e.g., a list of a few movies the user is currently considering for viewing. From a cognitive perspective, shortlists serve as digital short-term memory where users can offload the items under consideration – thereby decreasing their cognitive load. From a machine learning perspective, adding items to the shortlist generates a new implicit feedback signal as a by-product of exploration and decision making which can improve recommendation quality. Shortlisting therefore provides additional data for training recommendation systems without the increases in cognitive load that requesting explicit feedback would incur. <br>We perform an user study with a movie recommendation setup to compare interfaces that offer shortlist support with those that do not. From the user studies we conclude: (i) users make better decisions with a shortlist; (ii) users prefer an interface with shortlist support; and (iii) the additional implicit feedback from sessions with a shortlist improves the quality of recommendations by nearly a factor of two.
</div><br><b>Title: </b>Building a Theory of Job Rotation in Software Engineering from an Instrumental Case Study<br><b>Speaker: </b>朱天潼<br><b>Paper:</b>ICSE2016<a href="http://114.55.145.9:8080/References/seminar/ICSE2016/Building a Theory of Job Rotation in Software Engineering from an Instrumental Case Study.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611191.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Job Rotation is an organizational practice in which individuals are frequently moved from a job (or project) to another in the same organization. Studies in other areas have found that this practice has both negative and positive effects on individuals’ work. However, there are only few studies addressing this issue in software engineering so far. The goal of our study is to investigate the effects of job rotation on work related factors in software engineering by performing a qualitative case study on a large software organization that uses job rotation as an organizational practice. We interviewed senior managers, project managers, and software engineers that had experienced this practice. Altogether, 48 participants were involved in all phases of this research. Collected data was analyzed using qualitative coding techniques and the results were checked and validated with participants through member checking. Our findings suggest that it is necessary to find balance between the positive effects on work variety and learning opportunities, and negative effects on cognitive workload and performance. Further, the lack of feedback resulting from constant movement among projects and teams may have a negative impact on performance feedback. We conclude that job rotation is an important organizational practice with important positive results. However, managers must be aware of potential negative effects and deploy tactics to balance them. We discuss such tactics in this article.
</div><br><b>Title: </b>HD Maps Fine-grained Road Segmentation by Parsing Ground and Aerial Images<br><b>Speaker: </b>肖浩泉<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/HD Maps Fine-grained Road Segmentation by Parsing Ground and Aerial Images.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611192.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">In this paper we present an approach to enhance existing maps with fine grained segmentation categories such as parking spots and sidewalk, as well as the number and location of road lanes. Towards this goal, we propose an ef-ficient approach that is able to estimate these fine grained categories by doing joint inference over both, monocular aerial imagery, as well as ground images taken from a stereo camera pair mounted on top of a car. Important to this is reasoning about the alignment between the two types of imagery, as even when the measurements are taken with sophisticated GPS+IMU systems, this alignment is not suf-ficiently accurate. We demonstrate the effectiveness of our approach on a new dataset which enhances KITTI [8] with aerial images taken with a camera mounted on an airplane and flying around the city of Karlsruhe, Germany.
</div><br><b>Title: </b>Serving by local consensus in the public service location game<br><b>Speaker: </b>姜磊<br><b>Paper:</b>Sci.Rep.<a href="http://114.55.145.9:8080/References/seminar/Sci.Rep./Serving by local consensus in the public service location game.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611193.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">We discuss the issue of distributed and cooperative decision-making in a network game of public service location. Each node of the network can decide to host a certain public service incurring in a construction cost and serving all the neighboring nodes and itself. A pure consumer node has to pay a tax, and the collected tax is evenly distributed to all the hosting nodes to remedy their construction costs. If all nodes make individual best-response decisions, the system gets trapped in an inefficient situation of high tax level. Here we introduce a decentralized local-consensus selection mechanism which requires nodes to recommend their neighbors of highest local impact as candidate servers, and a node may become a server only if all its non-server neighbors give their assent. We demonstrate that although this mechanism involves only information exchange among neighboring nodes, it leads to socially efficient solutions with tax level approaching the lowest possible value. Our results may help in understanding and improving collective problem-solving in various networked social and robotic systems.
</div><br></section><section id="date2016-11-27" ><h3 ><hr>Date:2016-11-27<br></h3><b>Title: </b>Link Prediction in Social Networks using Computationally Efficient Topological Features<br><b>Speaker: </b>赵明浩<br><b>Paper:</b>IEEE<a href="http://114.55.145.9:8080/References/seminar/IEEE/Link Prediction in Social Networks using Computationally Efficient Topological Features.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611270.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Online social networking sites have become increas-ingly popular over the last few years. As a result, new interdisci-plinary research directions have emerged in which social network analysis methods are applied to networks containing hundreds millions of users. Unfortunately, links between individuals may be missing either due to imperfect acquirement processes or because they are not yet reflected in the online network (i.e., friends in real-world did not form a virtual connection.) Existing link prediction techniques lack the scalability required for full application on a continuously growing social network. <br>The primary bottleneck in link prediction techniques is ex-tracting structural features required for classifying links. In this paper we propose a set of simple, easy-to-compute structural features, that can be analyzed to identify missing links. We show that by using simple structural features, a machine learning classifier can successfully identify missing links, even when applied to a hard problem of classifying links between individuals with at least one common friend. A new friends measure that we developed is shown to be a good predictor for missing links. An evaluation experiment was performed on five large Social Networks datasets: Facebook, Flickr, YouTube, Academia and TheMarker. Our methods can provide social network site operators with the capability of helping users to find known, offline contacts and to discover new friends online. They may also be used for exposing hidden links in an online social network. Index Terms —Link Prediction, HiddenLinks, Social Networks, Supervised Learning.
</div><br><b>Title: </b>Venting Weight Analyzing the Discourse of an Online Weight Loss Forum<br><b>Speaker: </b>靳继伟<br><b>Paper:</b>AAAI2016<a href="http://114.55.145.9:8080/References/seminar/AAAI2016/Venting Weight Analyzing the Discourse of an Online Weight Loss Forum.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611271.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Online social communities are becoming increasingly popular platforms for people to share information, seek emotional support, and maintain accountability for losing weight. Studying the discourse in these communities can offer insights on how users benefit from using these applications. This paper presents an analysis of language and discourse patterns in forum posts by users who lose weight and keep it off versus users with fluctuating weight dynamics. In contrast to prior studies, we have access to the weekly self-reported check-in weights of users along with their forum posts. This paper also presents a study on how goal-oriented forums are different from general online forums in terms of language markers. Our results reveal differences about how the types of posts made by users vary along with their weight-loss patterns. These insights are closely related to the power dynamics of social interactions and can enable better design of weight-loss applications thereby contributing to a healthy society. 
</div><br><b>Title: </b>Image Question Answering using Convolutional Neural Network with Dynamic Parameter Prediction<br><b>Speaker: </b>李甫宪<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/Image Question Answering using Convolutional Neural Network with Dynamic Parameter Prediction.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611272.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">We tackle image question answering (ImageQA) problem by learning a convolutional neural network (CNN) with a dynamic parameter layer whose weights are determined adaptively based on questions. For the adaptive parameter prediction, we employ a separate parameter prediction network, which consists of gated recurrent unit (GRU) taking a question as its input and a fully-connected layer generating a set of candidate weights as its output. However, it is challenging to construct a parameter prediction network for a large number of parameters in the fully-connected dynamic parameter layer of the CNN. We reduce the complexity of this problem by incorporating a hashing technique, where the candidate weights given by the parameter prediction network are selected using a predefined hash function to determine individual weights in the dynamic parameter layer. The proposed network—joint network with the CNN for ImageQA and the parameter prediction network— is trained end-to-end through back-propagation, where its weights are initialized using a pre-trained CNN and GRU. The proposed algorithm illustrates the state-of-the-art performance on all available public ImageQA benchmarks.
</div><br><b>Title: </b>Higher-order organization of complex networks<br><b>Speaker: </b>郑永立<br><b>Paper:</b>Science<a href="http://114.55.145.9:8080/References/seminar/Science/Higher-order organization of complex networks.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201611273.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Networks are a fundamental tool for understanding and modeling complex systems in physics, biology, neuroscience, engineering, and social science. Many networks are known to exhibit rich, lower-order connectivity patterns that can be captured at the level of individual nodes and edges. However, higher-order organization of complex networks—at the level of small network subgraphs—remains largely unknown. Here, we develop a generalized framework for clustering networks on the basis of higher-order connectivity patterns. This framework provides mathematical guarantees on the optimality of obtained clusters and scales to networks with billions of edges. The framework reveals higher-order organization in a number of networks, including information propagation units in neuronal networks and hub structure in transportation networks. Results show that networks exhibit rich higher-order organizational structures that are exposed by clustering based on higher-order connectivity patterns.
</div><br></section><section id="date2016-12-03" ><h3 ><hr>Date:2016-12-03<br></h3><b>Title: </b>Exploring Limits to Prediction in Complex Social Systems<br><b>Speaker: </b>樊坤鹏<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/Exploring Limits to Prediction in Complex Social Systems.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612030.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">How predictable is success in complex social systems? In spite of a recent profusion of prediction studies that exploit online social and information network data, this question remains unanswered, in part because it has not been adequately specified. In this paper we attempt to clarify the question by presenting a simple stylized model of success that attributes prediction error to one of two generic sources: insu!ciency of available data and/or models on the one hand; and inherent unpredictability of complex social systems on the other. We then use this model to motivate an illustrative empirical study of information cascade size prediction on Twitter. Despite an unprecedented volume of information about users, content, and past performance, our best performing models can explain less than half of the variance in cascade sizes. In turn, this result suggests that even with unlimited data predictive performance would be bounded well below deterministic accuracy. Finally, we explore this potential bound theoretically using simulations of a di↵usion process on a random scale free network similar to Twitter. We show that although higher predictive power is possible in theory, such performance requires a homogeneous system and perfect ex-ante knowledge of it: even a small degree of uncertainty in estimating product quality or slight variation in quality across products leads to substantially more restrictive bounds on predictability. We conclude that realistic bounds on predictive accuracy are not dissimilar from those we have obtained empirically, and that such bounds for other complex social systems for which data is more di!cult to obtain are likely even lower.
</div><br><b>Title: </b>Automatic Summary Generation for Scientific Data Charts<br><b>Speaker: </b>Paul<br><b>Paper:</b>AAAI2016<a href="http://114.55.145.9:8080/References/seminar/AAAI2016/Automatic Summary Generation for Scientific Data Charts.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612031.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Scientific charts in the web, whether as images or em-bedded in digital documents, contain valuable informa-tion that is not fully available to information retrieval tools. The information used to describe these charts is typically extracted from the image metadata rather than the information the graphic was initially designed to express. The problem of understanding digital charts found in scholarly documents, and inferring useful tex-tual information from their graphical components is the focus of this study. We present an approach to automat-ically read the chart data, specifically bar charts, and provide the user with a textual summary of the chart. The proposed method follows a knowledge discovery approach that relies on a versatile graph representation of the chart. This representation is derived from ana-lyzing a chart’s original data values, from which useful features are extracted. The data features are in turn used to construct a semantic-graph. To generate a summary, the semantic-graph of the chart is mapped to appropri-ately crafted protoforms, which are constructs based on fuzzy logic. We verify the effectiveness of our frame-work by conducting experiments on bar charts extracted from over 1 , 000 PDF documents. Our preliminary re-sults show that, under certain assumptions, 83% of the produced summaries provide plausible descriptions of the bar charts.
</div><br><b>Title: </b>Structural Neighborhood Based Classification of Nodes in a Network<br><b>Speaker: </b>姜磊<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/Structural Neighborhood Based Classification of Nodes in a Network.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612032.pdf">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Classification of entities based on the underlying network structure is an important problem. Networks encountered in practice are sparse and have many missing and noisy links. Statistical learning techniques have been used in intranetwork classification; however, they typically exploit only the local neighborhood, so may not perform well. In this paper, we propose a novel structural neighborhood-based classifier learning using a random walk. For classifying a node, we take a random walk from the node and make a decision based on how nodes in the respective k-level neighborhood are labeled. We observe that random walks of short length are helpful in classification. Emphasizing role of longer random walks may cause the underlying Markov chain to converge to a stationary distribution. Considering this, we take a lazy random walk based approach with variable termination probability for each node, based on the node’s structural properties including its degree. Our experimental study on real world datasets demonstrates the superiority of the proposed approach over the existing state-of-the-art approaches.
</div><br><b>Title: </b>Sparse Coding for Third-order Super-symmetric Tensor Descriptors with Application to Texture Recognition<br><b>Speaker: </b>方宾伟<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/Sparse%20Coding%20for%20Third-order%20Super-symmetric%20Tensor%20Descriptors%20with%20Application%20to%20Texture%20Recognition.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612033.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Super-symmetric tensors – a higher-order extension of scatter matrices – are becoming increasingly popular in machine learning and computer vision for modeling data statistics, co-occurrences, or even as visual descriptors. They were shown recently to outperform second-order approaches [18], however, the size of these tensors are exponential in the data dimensionality, which is a signifi-cant concern. In this paper, we study third-order supersymmetric tensor descriptors in the context of dictionary learning and sparse coding. For this purpose, we propose a novel non-linear third-order texture descriptor. Our goal is to approximate these tensors as sparse conic combinations of atoms from a learned dictionary. Apart from the significant benefits to tensor compression that this framework offers, our experiments demonstrate that the sparse coefficients produced by this scheme lead to better aggregation of high-dimensional data and showcase superior performance on two common computer vision tasks compared to the state of the art.</div><br><b>Title: </b>Automated Parameter Optimization of Classification Techniques for Defect Prediction Models<br><b>Speaker: </b>周鸣鸣<br><b>Paper:</b>ICSE2016<a href="http://114.55.145.9:8080/References/seminar/ICSE2016/Automated Parameter Optimization of Classification Techniques for Defect Prediction Models.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612034.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Defect prediction models are classifiers that are trained to identify defect-prone software modules. Such classifiers have configurable parameters that control their characteristics (e.g. , the number of trees in a random forest classifier). Recent studies show that these classifiers may underperform due to the use of suboptimal default parameter settings. How-ever, it is impractical to assess all of the possible settings in the parameter spaces. In this paper, we investigate the performance of defect prediction models where Caret — an automated parameter optimization technique — has been applied. Through a case study of 18 datasets from systems that span both proprietary and open source domains, we find that (1) Caret improves the AUC performance of de-fect prediction models by as much as 40 percentage points; (2) Caret-optimized classifiers are at least as stable as (with 35% of them being more stable than) classifiers that are trained using the default settings; and (3) Caret increases the likelihood of producing a top-performing classifier by as much as 83%. Hence, we conclude that parameter settings can indeed have a large impact on the performance of de-fect prediction models, suggesting that researchers should experiment with the parameters of the classification tech-niques. Since automated parameter optimization techniques like Caret yield substantially benefits in terms of perfor-mance improvement and stability, while incurring a manage-able additional computational cost, they should be include d in future defect prediction studies.
</div><br><b>Title: </b>Influence maximization in complex networks through optimal percolation<br><b>Speaker: </b>王金宝<br><b>Paper:</b>Nature<a href="http://114.55.145.9:8080/References/seminar/Nature/Influence maximization in complex networks through optimal percolation.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">The whole frame of interconnections in complex networks hinges on a specific set of structural nodes, much smaller than the total size, which, if activated, would cause the spread of information to the whole network 1 , or, if immunized, would prevent the diffusion of a large scale epidemic 2,3 . Localizing this optimal, that is, min-imal, set of structural nodes, called influencers, is one of the most important problems in network science 4,5 . Despite the vast use of heuristic strategies to identify influential spreaders 6–14 , the prob-lem remains unsolved. Here we map the problem onto optimal percolation in random networks to identify the minimal set of influencers, which arises by minimizing the energy of a many-body system, where the form of the interactions is fixed by the non-backtracking matrix 15 of the network. Big data analyses reveal that the set of optimal influencers is much smaller than the one pre-dicted by previous heuristic centralities. Remarkably, a large num-ber of previously neglected weakly connected nodes emerges among the optimal influencers. These are topologically tagged as low-degree nodes surrounded by hierarchical coronas of hubs, and are uncovered only through the optimal collective interplay of all the influencers in the network. The present theoretical framework may hold a larger degree of universality, being applicable to other hard optimization problems exhibiting a continuous transition from a known phase 16.
</div><br></section><section id="date2016-12-10" ><h3 ><hr>Date:2016-12-10<br></h3><b>Title: </b>Unfolding large-scale online collaborative human dynamics<br><b>Speaker: </b>周鸣鸣<br><b>Paper:</b>PNAS<a href="http://114.55.145.9:8080/References/seminar/PNAS/Unfolding large-scale online collaborative human dynamics.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612100.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Large-scale interacting human activities underlie all social and economic phenomena, but quantitative understanding of regular patterns and mechanism is very challenging and still rare. Self-organized online collaborative activities with a precise record of event timing provide unprecedented opportunity. Our empirical analysis of the history of millions of updates in Wikipedia shows a universal double–power-law distribution of time intervals between consecutive updates of an article. We then propose a generic model to unfold collaborative human activities into three modules: (i) individual behavior characterized by Poissonian initiation of an action, (ii) human interaction captured by a cascading response to previous actions with a power-law waiting time, and (iii) population growth due to the increasing number of interacting individuals. This unfolding allows us to obtain an analytical formula that is fully supported by the universal patterns in empirical data. Our modeling approaches reveal “simplicity” beyond complex interacting human activities.
</div><br><b>Title: </b>TribeFlow Mining & Predicting User Trajectories<br><b>Speaker: </b>王金宝<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/TribeFlow Mining & Predicting User Trajectories.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612101.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Which song will Smith listen to next? Which restaurant will Alice go to tomorrow? Which product will John click next? These applications have in common the prediction of user trajectories that are in a constant state of flux over a hidden network (e.g. website links, geographic location). Moreover, what users are doing now may be unrelated to what they will be doing in an hour from now. Mindful of these challenges we propose TribeFlow, a method designed to cope with the complex challenges of learning personalized predictive models of non-stationary, transient, and time-heterogeneous user trajectories. TribeFlow is a general method that can perform next product recommendation, next song recommendation, next location prediction, and general arbitrary-length user trajectory prediction without domain-specific knowledge. TribeFlow is more accurate and up to 413× faster than top competitors.
</div><br><b>Title: </b>Discovering Relevant Hashtags for Health Concepts A Case Study of Twitter<br><b>Speaker: </b>王金宝<br><b>Paper:</b>AAAI2016<a href="http://114.55.145.9:8080/References/seminar/AAAI2016/Discovering Relevant Hashtags for Health Concepts A Case Study of Twitter.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612102.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Hashtags are useful in many applications, such as tweet classification, clustering, searching, indexing and social network analysis. This study seeks to recommend relevant Twitter hashtags for health-related keywords based on distributed language representations, generated by the state-ofthe-art Deep Learning technology. The word embeddings are built from billions of tweet words without supervision. To the best of our knowledge, this is the first study of applying distributed language representations to recommending hashtags for keywords. The experiment showed that this approach outperformed the baseline approach that is based on keyword and hashtag co-occurrence in tweets. 
</div><br><b>Title: </b>Analyzing NIH Funding Patterns over Time with Statistical Text Analysis<br><b>Speaker: </b>虞烨炜<br><b>Paper:</b>AAAI2016<a href="http://114.55.145.9:8080/References/seminar/AAAI2016/Analyzing NIH Funding Patterns over Time with Statistical Text Analysis.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612103.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">In the past few years various government funding organi-zations such as the U.S. National Institutes of Health and the U.S. National Science Foundation have provided access to large publicly-available online databases documenting the grants that they have funded over the past few decades. These databases provide an excellent opportunity for the application of statistical text analysis techniques to infer useful quanti-tative information about how funding patterns have changed over time. In this paper we analyze data from the National Cancer Institute (part of National Institutes of Health) and show how text classification techniques provide a useful start-ing point for analyzing how funding for cancer research has evolved over the past 20 years in the United States.
</div><br><b>Title: </b>Linking Users Across Domains with Location Data Theory and validation<br><b>Speaker: </b>郑永立<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/Linking Users Across Domains with Location Data Theory and validation.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612104.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Linking accounts of the same user across datasets { even when personally identifying information is removed or un-available { is an important open problem studied in many contexts. Beyond many practical applications, (such as cross domain analysis, recommendation, and link prediction), un-derstanding this problem more generally informs us on the privacy implications of data disclosure. Previous work has typically addressed this question using either di erent por-tions of the same dataset or observing the same behavior across thematically similar domains. In contrast, the general cross-domain case where users have di erent pro les inde-pendently generated from a common but unknown pattern raises new challenges, including difficulties in validation, and remains under-explored. <br>In this paper, we address the reconciliation problem for location-based datasets and introduce a robust method for this general setting. Location datasets are a particularly fruitful domain to study: such records are frequently pro-duced by users in an increasing number of applications and are highly sensitive, especially when linked to other data-sets. Our main contribution is a generic and self-tunable algorithm that leverages any pair of sporadic location-based datasets to determine the most likely matching between the users it contains. While making very general assumptions on the patterns of mobile users, we show that the maximum weight matching we compute is provably correct. Although true cross-domain datasets are a rarity, our experimental evaluation uses two entirely new data collections, including one we crawled, on an unprecedented scale. The method we design outperforms naive rules and prior heuristics. As it combines both sparse and dense properties of location-based data and accounts for probabilistic dynamics of observation, it can be shown to be robust even when data gets sparse.
</div><br><b>Title: </b>Anomaly Detection Using Program Control Flow Graph Mining from Execution Logs<br><b>Speaker: </b>朱天潼<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/Anomaly Detection Using Program Control Flow Graph Mining from Execution Logs.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">We focus on the problem of detecting anomalous run-time behav-ior of distributed applications from their execution logs. Specifi-cally we mine templates and template sequences from logs to form a control flow graph (cfg) spanning distributed components. This cfg represents the baseline healthy system state and is used to flag devi-ations from the expected behavior of runtime logs. The novelty in our work stems from the new techniques employed to: (1) overcome the instrumentation requirements or application specific assumptions made in prior log mining approaches, (2) improve the accuracy of mined templates and the cfg in the presence of long parameters and high amount of interleaving respectively, and (3) improve by orders of magnitude the scalability of the cfg mining process in terms of volume of log data that can be processed per day. We evaluate our template and cfg mining approaches using (a) synthetic log traces and (b) multiple real-world log datasets collected at different layers of application stack. Results demonstrate that the template mining, cfg mining, and our anomaly detection algorithms have high accuracy. The distributed implementation of our pipeline is highly scalable and has more than 500 GB/day of log data process-ing capability even on a 10 low-end VM based (Spark + Hadoop) cluster.
</div><br><b>Title: </b>TI-POOLING:transformation-invariant pooling for feature learning in Convolutional Neural Networks<br><b>Speaker: </b>方宾伟<br><b>Paper:</b>Arxiv<a href="http://114.55.145.9:8080/References/seminar/Arxiv/TI-POOLING:transformation-invariant pooling for feature learning in Convolutional Neural Networks.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612106.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">In this paper we present a deep neural network topology that incorporates a simple to implement transformation-invariant pooling operator ( TI-POOLING ). This operator is able to efficiently handle prior knowledge on nuisance variations in the data, such as rotation or scale changes. Most current methods usually make use of dataset augmen-tation to address this issue, but this requires larger number of model parameters and more training data, and results in significantly increased training time and larger chance of under-or overfitting. The main reason for these drawbacks is that that the learned model needs to capture adequate features for all the possible transformations of the input. On the other hand, we formulate features in convolutional neural networks to be transformation-invariant. We achieve that using parallel siamese architectures for the considered transformation set and applying the TI-POOLING operator on their outputs before the fully-connected layers. We show that this topology internally finds the most optimal ”canon-ical” instance of the input image for training and therefore limits the redundancy in learned features. This more effi-cient use of training data results in better performance on popular benchmark datasets with smaller number of param-eters when comparing to standard convolutional neural net-works with dataset augmentation and to other baselines
</div><br><b>Title: </b>Part-Stacked CNN for Fine-Grained Visual Categorization<br><b>Speaker: </b>肖浩泉<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/Part-Stacked CNN for Fine-Grained Visual Categorization.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612107.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">In the context of fine-grained visual categorization, the ability to interpret models as human-understandable visual manuals is sometimes as important as achieving high clas-sification accuracy. In this paper, we propose a novel Part-Stacked CNN architecture that explicitly explains the fine-grained recognition process by modeling subtle differences from object parts. Based on manually-labeled strong part annotations, the proposed architecture consists of a fully convolutional network to locate multiple object parts and a two-stream classification network that encodes object-level and part-level cues simultaneously. By adopting a set of sharing strategies between the computation of multiple ob-ject parts, the proposed architecture is very efficient run-ning at 20 frames/sec during inference. Experimental re-sults on the CUB-200-2011 dataset reveal the effectiveness of the proposed architecture, from multiple perspectives of classification accuracy, model interpretability, and efficien-cy. Being able to provide interpretable recognition results in realtime, the proposed method is believed to be effective in practical applications.
</div><br></section><section id="date2016-12-17" ><h3 ><hr>Date:2016-12-17<br></h3><b>Title: </b>Weight prediction in complex networks based on neighbor set<br><b>Speaker: </b>赵明浩<br><b>Paper:</b>Nature<a href="http://114.55.145.9:8080/References/seminar/Nature/Weight prediction in complex networks based on neighbor set.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">Link weights are essential to network functionality, so weight prediction is important for understanding weighted networks given incomplete real-world data. In this work, we develop a novel method for weight prediction based on the local network structure, namely, the set of neighbors of each node. The performance of this method is validated in two cases. In the first case, some links are missing altogether along with their weights, while in the second case all links are known and weight information is missing for some links. Empirical experiments on real-world networks indicate that our method can provide accurate predictions of link weights in both cases.
</div><br><b>Title: </b>Approximate Personalized PageRank on Dynamic Graphs<br><b>Speaker: </b>靳继伟<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/Approximate Personalized PageRank on Dynamic Graphs.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612171.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">We propose and analyze two algorithms for maintaining approximate Personalized PageRank (PPR) vectors on a dynamic graph, where edges are added or deleted. Our algorithms are natural dynamic versions of two known local variations of power iteration. One, Forward Push, propagates probability mass forwards along edges from a source node, while the other, Reverse Push, propagates local changes backwards along edges from a target. In both variations, we maintain an invariant between two vectors, and when an edge is updated, our algorithm first modifies the vectors to restore the invariant, then performs any needed local push operations to restore accuracy.<br>For Reverse Push, we prove that for an arbitrary directed graph in a random edge model, or for an arbitrary undirected graph, given a uniformly random target node t, the cost to maintain a PPR vector to t of additive error ε as k edges are updated is O(k + d/ε), where d is the average degree of the graph. This is O(1) work per update, plus the cost of computing a reverse vector once on a static graph. For Forward Push, we show that on an arbitrary undirected graph, given a uniformly random start node s, the cost to maintain a PPR vector from s of degree-normalized error ε as k edges are updated is O(k + 1/ε), which is again O(1) per update plus the cost of computing a PPR vector once on a static graph. 
</div><br><b>Title: </b>Foraging and Navigations, Fundamentally Developers’ Predictions of Value and Cost<br><b>Speaker: </b>周鸣鸣<br><b>Paper:</b>ACM<a href="http://114.55.145.9:8080/References/seminar/ACM/Foraging and Navigations, Fundamentally Developers’ Predictions of Value and Cost.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">Empirical studies have revealed that software developers spend 35%–50% of their time navigating through source code during development activities, yet fundamental questions remain: Are these percentages too high, or simply inherent in the nature of software development? Are there factors that somehow determine a lower bound on how effectively developers can navigate a given information space? Answering questions like these requires a theory that captures the core of developers’ navigation decisions. Therefore, we use the central proposition of Information Foraging Theory to investigate developers’ ability to predict the value and cost of their navigation decisions. Our results showed that over 50% of developers’ navigation choices produced less value than they had predicted and nearly 40% cost more than they had predicted. We used those results to guide a literature analysis, to investigate the extent to which these challenges are met by current research efforts, revealing a new area of inquiry with a rich and crosscutting set of research challenges and open problems. 
</div><br></section><section id="date2016-12-24" ><h3 ><hr>Date:2016-12-24<br></h3><b>Title: </b>User Characterization for Online Social Networks<br><b>Speaker: </b>郑永立<br><b>Paper:</b>Arxiv<a href="http://114.55.145.9:8080/References/seminar/Arxiv/User Characterization for Online Social Networks.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612240.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Online social network analysis has attracted great attention with a vast number of users sharing information and availability of APIs that help to crawl online social network data. In this paper, we study the research studies that are helpful for user characterization as online users may not always reveal their true identity or attributes. We especially focused on user attribute determination such as gender, age, etc.; user behavior analysis such as motives for deception; mental models that are indicators of user behavior; user catego rization such as bots vs. humans; and entity matching on dierent social networks. We believe our summary of analysis of user characterization will provide important insights to researchers and better services to online users.
</div><br><b>Title: </b>You Only Look Once: Unified, Real-Time Object Detection<br><b>Speaker: </b>李甫宪<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/You Only Look Once: Unified, Real-Time Object Detection.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612241.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance.<br>Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.
</div><br><b>Title: </b>Lexis An Optimization Framework for Discovering the Hierarchical Structure of Sequential Data<br><b>Speaker: </b>樊坤鹏<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/Lexis An Optimization Framework for Discovering the Hierarchical Structure of Sequential Data.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612242.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Data represented as strings abounds in biology, linguistics, document mining, web search and many other fields. Such data often have a hierarchical structure, either because they were artificially designed and composed in a hierarchical manner or because there is an underlying evolutionary process that creates repeatedly more complex strings from simpler substrings. We propose a framework, referred to as Lexis, that produces an optimized hierarchical representation of a given set of “target” strings. The resulting hierarchy, “Lexis-DAG”, shows how to construct each target through the concatenation of intermediate substrings, minimizing the total number of such concatenations or DAG edges. The Lexis optimization problem is related to the smallest grammar problem. After we prove its NP-hardness for two cost formulations, we propose an efficient greedy algorithm for the construction of Lexis-DAGs. We also consider the problem of identifying the set of intermediate nodes (substrings) that collectively form the “core” of a LexisDAG, which is important in the analysis of Lexis-DAGs. We show that the Lexis framework can be applied in diverse applications such as optimized synthesis of DNA fragments in genomic libraries, hierarchical structure discovery in protein sequences, dictionary-based text compression, and feature extraction from a set of documents.
</div><br><b>Title: </b>Automatically Augmenting Titles of Research Papers for Better Discovery<br><b>Speaker: </b>赵明浩<br><b>Paper:</b>AAAI2016<a href="http://114.55.145.9:8080/References/seminar/AAAI2016/Automatically Augmenting Titles of Research Papers for Better Discovery.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">It is well known that the title of an article impacts how well it is discovered by potential readers and read. With both peo-ple and search engines, acting on behalf of people, accessing papers from digital libraries, it is important that the paper titles should promote discovery. In this paper, we investigate the characteristics of titles of AI papers and then propose au-tomatic ways to augment them so that they can be better indexed and discovered by users. A user study with researchers shows that they overwhelmingly prefer the augmented titles over the originals for being more helpful.
</div><br><b>Title: </b>Object Skeleton Extraction in Natural Images by Fusing Scale-associated Deep Side Outputs<br><b>Speaker: </b>Paul<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/Object Skeleton Extraction in Natural Images by Fusing Scale-associated Deep Side Outputs.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612244.ppt">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Object skeleton is a useful cue for object detection, com-plementary to the object contour, as it provides a structural representation to describe the relationship among object parts. While object skeleton extraction in natural images is a very challenging problem, as it requires the extractor to be able to capture both local and global image contex-t to determine the intrinsic scale of each skeleton pixel. Existing methods rely on per-pixel based multi-scale fea-ture computation, which results in difficult modeling and high time consumption. In this paper, we present a fully convolutional network with multiple scale-associated side outputs to address this problem. By observing the rela-tionship between the receptive field sizes of the sequential stages in the network and the skeleton scales they can cap-ture, we introduce a scale-associated side output to each stage. We impose supervision to different stages by guiding the scale-associated side outputs toward groundtruth skele-tons of different scales. The responses of the multiple scale-associated side outputs are then fused in a scale-specific way to localize skeleton pixels with multiple scales effec-tively. Our method achieves promising results on two skele-ton extraction datasets, and significantly outperforms other competitors.
</div><br><b>Title: </b>Smart Reply: Automated Response Suggestion for Email<br><b>Speaker: </b>姜磊<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/Smart Reply: Automated Response Suggestion for Email.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612245.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">In this paper we propose and investigate a novel end-to-end method for automatically generating short email responses, called Smart Reply. It generates semantically diverse sug-gestions that can be used as complete email responses with just one tap on mobile. The system is currently used in In-box by Gmail and is responsible for assisting with 10% of all mobile responses. It is designed to work at very high throughput and process hundreds of millions of messages daily. The system exploits state-of-the-art, large-scale deep learning.<br> We describe the architecture of the system as well as the challenges that we faced while building it, like response di-versity and scalability. We also introduce a new method for semantic clustering of user-generated content that requires only a modest amount of explicitly labeled data
</div><br><b>Title: </b>Toward Link Predictability of Complex Networks<br><b>Speaker: </b>周鸣鸣<br><b>Paper:</b>PNAS<a href="http://114.55.145.9:8080/References/seminar/PNAS/Toward Link Predictability of Complex Networks.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612246.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">The organization of real networks usually embodies both regu-larities and irregularities, and, in principle, the former can be modeled. The extent to which the formation of a network can be explained coincides with our ability to predict missing links. To understand network organization, we should be able to estimate link predictability. We assume that the regularity of a network is reflected in the consistency of structural features before and after a random removal of a small set of links. Based on the perturbation of the adjacency matrix, we propose a universal structural consistency index that is free of prior knowledge of network organization. Extensive experiments on disparate real-world networks demonstrate that ( i ) structural consistency is a good estimation of link predictability and ( ii ) a derivative algo-rithm outperforms state-of-the-art link prediction methods in both accuracy and robustness. This analysis has further applica-tions in evaluating link prediction algorithms and monitoring sud-den changes in evolving network mechanisms. It will provide unique fundamental insights into the above-mentioned academic research fields, and will foster the development of advanced in-formation filtering technologies of interest to information tech-nology practitioners
</div><br><b>Title: </b>Mining Community-Based Top-k Experts<br><b>Speaker: </b>靳继伟<br><b>Paper:</b>Springer<a href="http://114.55.145.9:8080/References/seminar/Springer/Mining Community-Based Top-k Experts.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612247.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Online Question Answering Systems are very popular and helpful for programming community. In these systems, users can post questions, answer the questions, collaboratively tag the questions, and vote for quality answers. This paper implements a link structure-based Top-k Experts and Learners finding algorithm using Stanford Network Analysis Project (SNAP) Library. Experiments are done on real data taken from Stack Overflow that mainly focuses on computer programming and the results show that link analysis techniques are more suitable for analyzing online question answering systems.
</div><br></section><section id="date2016-12-31" ><h3 ><hr>Date:2016-12-31<br></h3><b>Title: </b>Urban Pulse: Capturing the Rhythm of Cities<br><b>Speaker: </b>周鸣鸣<br><b>Paper:</b>Arxiv<a href="http://114.55.145.9:8080/References/seminar/Arxiv/Urban Pulse: Capturing the Rhythm of Cities.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612310.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">Cities are inherently dynamic. Interesting patterns of behavior typically manifest at several key areas of a city over multiple temporal resolutions. Studying these patterns can greatly help a variety of experts ranging from city planners and architects to human behavioral experts. Recent technological innovations have enabled the collection of enormous amounts of data that can help in these studies. However, techniques using these data sets typically focus on understanding the data in the context of the city, thus failing to capture the dynamic aspects of the city. The goal of this work is to instead understand the city in the context of multiple urban data sets. To do so, we define the concept of an “urban pulse” which captures the spatio-temporal activity in a city across multiple temporal resolutions. The prominent pulses in a city are obtained using the topology of the data sets, and are characterized as a set of beats. The beats are then used to analyze and compare different pulses. We also design a visual exploration framework that allows users to explore the pulses within and across multiple cities under different conditions. Finally, we present three case studies carried out by experts from two different domains that demonstrate the utility of our framework.
</div><br><b>Title: </b>The Effect of Recommendations on Network Structure<br><b>Speaker: </b>虞烨炜<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/The Effect of Recommendations on Network Structure.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">Online social networks regularly o er users personalized, al-gorithmic suggestions of whom to connect to. Here we ex-amine the aggregate e ects of such recommendations on net-work structure, focusing on whether these recommendations increase the popularity of niche users or, conversely, those who are already popular. We investigate this issue by empir-ically and theoretically analyzing abrupt changes in Twit-ter's network structure around the mid-2010 introduction of its \Who to Follow" feature. We nd that users across the popularity spectrum bene tted from the recommendations; however, the most popular users pro ted substantially more than average. We trace this \rich get richer" phenomenon to three intertwined factors. First, as is typical of network rec-ommenders, the system relies on a \friend-of-friend"-style algorithm, which we show generally results in users being recommended proportional to their degree. Second, we nd that the baseline growth rate of users is sublinear in degree. This mismatch between the recommender and the natural network dynamics thus alters the structural evolution of the network. Finally, we nd that people are much more likely to respond positively to recommendations for popular users| perhaps because of their greater name recognition|further amplifying the cumulative advantage of well-known individ-uals.
</div><br><b>Title: </b>Come-and-Go Patterns of Group Evolution A Dynamic Model<br><b>Speaker: </b>郑永立<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/Come-and-Go Patterns of Group Evolution A Dynamic Model.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/201612312.pptx">[PPT]</a><br><b>Abstract:<br> </b><div style="text-align:justify">How do social groups, such as Facebook groups and Wechat groups, dynamically evolve over time? How do people join the social groups, uniformly or with burst? What is the pattern of people quitting from groups? Is there a simple u-niversal model to depict the come-and-go patterns of various groups?<br> In this paper, we examine temporal evolution patterns of more than 100 thousands social groups with more than 10 million users. We surprisingly nd that the evolution patterns of real social groups goes far beyond the classic dynamic models like SI and SIR. For example, we observe both di usion and non-di usion mechanism in the group joining process, and power-law decay in group quitting pro-cess, rather than exponential decay as expected in SIR mod-el. Therefore we propose a new model comeNgo , a concise yet exible dynamic model for group evolution. Our model has the following advantages: (a) uni cation power: it gen-eralizes earlier theoretical models and di erent joining and quitting mechanisms we nd from observation. (b) succinct-ness and interpretability: it contains only six parameters with clear physical meanings. (c) accuracy: it can capture various kinds of group evolution patterns preciously and the goodness of t increase by 58% over baseline. (d) useful-ness: it can be used in multiple application scenarios such as forecasting and pattern discovery
</div><br><b>Title: </b>Transfer Knowledge between Cities<br><b>Speaker: </b>樊坤鹏<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/Transfer Knowledge between Cities.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">The rapid urbanization has motivated extensive research on urban computing. It is critical for urban computing tasks to unlock the power of the diversity of data modalities generated by di ff erent sources in urban spaces, such as vehicles and humans. However, we are more likely to encounter the label scarcity problem and the data insu ffi ciency problem when solving an urban computing task in a city where services and infrastructures are not ready or just built. In this paper, we propose a FLexible multimOdal tRAnsfer Learning (FLORAL) method to transfer knowledge from a city where there exist su ffi cient multimodal data and labels to similar kind of cities to fully alleviate the problems of label scarcity and data insu ffi cien-cy. FLORAL learns semantically related dictionaries for multiple modalities from a source domain and simultaneously transfers the dictionaries and labelled instances from the source into a target do-main. We evaluate the proposed method with a real-world study of air quality prediction.
</div><br><b>Title: </b>Collaborative Expert Recommendation<br><b>Speaker: </b>靳继伟<br><b>Paper:</b>Springer<a href="http://114.55.145.9:8080/References/seminar/Springer/Collaborative Expert Recommendation.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">With the development of Internet, users can share knowledge by asking and answering questions on community question answering (CQA) websites. How to find related experts to contribute their answers is hence worthy of studying. In this paper, we propose a recommendation algorithm called collaborative expert recommendation (CER) for this purpose. We take full advantage of the heterogeneous information including question tags, content, answer’s votes, which are considered important for identifying experts. Moreover, we combine such information by a causal assumption of questions and answers, and inner connection exploitation among different types of information such as (questioner, question), (answer, question) and (answerer, question, answer) correlations, which are more explicable and reasonable comparing with the existing methods. Experiments carried out on six real-world datasets prove that CER has a better performance.
</div><br></section><section id="date2017-01-07" ><h3 ><hr>Date:2017-01-07<br></h3><b>Title: </b>Addressing Complex and Subjective Product-Related Queries with customer Reviews<br><b>Speaker: </b>朱天潼<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/Addressing Complex and Subjective Product-Related Queries with customer Reviews.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">Online reviews are often our first port of call when considering products and purchases online. When evaluating a potential pur-chase, we may have a specific query in mind, e.g. ‘will this baby seat fit in the overhead compartment of a 747?’ or ‘will I like this album if I liked Taylor Swift’s 1989 ?’. To answer such questions we must either wade through huge volumes of consumer reviews hoping to find one that is relevant, or otherwise pose our question directly to the community via a Q/A system. In this paper we hope to fuse these two paradigms: given a large volume of previously answered queries about products, we hope to automatically learn whether a review of a product is relevant to a given query. We formulate this as a machine learning problem using a mixture-of-experts-type framework—here each review is an ‘expert’ that gets to vote on the response to a particular query; simultaneously we learn a relevance function such that ‘relevant’ reviews are those that vote correctly. At test time this learned rele-vance function allows us to surface reviews that are relevant to new queries on-demand. We evaluate our system, Moqa , on a novel cor-pus of 1.4 million questions (and answers) and 13 million reviews. We show quantitatively that it is effective at addressing both binary and open-ended queries, and qualitatively that it surfaces reviews that human evaluators consider to be relevant.
</div><br><b>Title: </b>A Multi-Task Learning Formulation for Survival Analysis<br><b>Speaker: </b>Paul<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/A Multi-Task Learning Formulation for Survival Analysis.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">Predicting the occurrence of a particular event of interest at future time points is the primary goal of survival analysis. The presence of incomplete observations due to time limi-tations or loss of data traces is known as censoring which brings unique challenges in this domain and di erentiates survival analysis from other standard regression methods. The popularly used survival analysis methods such as Cox proportional hazard model and parametric survival regres-sion su er from some strict assumptions and hypotheses that are not realistic in most of the real-world applications. To overcome the weaknesses of these two types of methods, we reformulate the survival analysis problem as a multi-task learning problem and propose a new multi-task learning based formulation to predict the survival time by estimating the survival status at each time interval during the study du-ration. We propose an indicator matrix to enable the multi-task learning algorithm to handle censored instances and in-corporate some of the important characteristics of survival problems such as non-negative non-increasing list structure into our model through max-heap projection. We employ the l 2 ; 1-norm penalty to learn a shared representation across related tasks and hence select important features and alle-viate over-tting in high-dimensional feature spaces; thus, reducing the prediction error of each task. To eachciently handle the two non-smooth constraints, in this paper, we propose an optimization method which employs Alternat-ing Direction Method of Multipliers (ADMM) algorithm to solve the proposed multi-task learning problem. We demon-strate the performance of the proposed method using real-world microarray gene expression datasets and show that our methods outperform state-of-the-art methods.
</div><br><b>Title: </b>Inflow and Retention in OSS Communities with Commercial involvement A Case Study of Three Hybrid Projects<br><b>Speaker: </b>周鸣鸣<br><b>Paper:</b>ICSE2016<a href="http://114.55.145.9:8080/References/seminar/ICSE2016/Inflow and Retention in OSS Communities with Commercial involvement A Case Study of Three Hybrid Projects.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">Open-source projects are often supported by companies, but such involvement often affects the robust contributor inflow needed to sustain the project and sometimes prompts key contributors to leave. To capture user innovation and to maintain quality of software and productivity of teams, these projects need to attract and retain contributors. Aim: We want to understand and quantify how inflow and retention are shaped by policies and actions of companies in three application server projects. Method: We identified three hybrid projects implementing the same JavaEE specification and used published literature, online materials, and interviews to quantify actions and policies companies used to get involved. We collected project repository data, analyzed affiliation history of project participants, and used generalized linear models and survival analysis to measure contributor inflow and retention. Results: We identified coherent groups of policies and actions undertaken by sponsoring companies as three models of community involvement and quantified tradeoffs between the inflow and retention each model provides. We found that full control mechanisms and high intensity of commercial involvement were associated with a decrease of external inflow and with improved retention. However, a shared control mechanism was associated with increased external inflow contemporaneously with the increase of commercial involvement. Implications: Inspired by anaturalexperiment,our methods enabled us to quantify aspects of the balance between community and private interests in open-source software projects and provide clear implications for the structure of future open-source communities.
</div><br><b>Title: </b>HeteroSales Utilizing Heterogeneous Social Networks to Identify the Next Enterprise Customer<br><b>Speaker: </b>赵明浩<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/HeteroSales Utilizing Heterogeneous Social Networks to Identify the Next Enterprise Customer.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">Nowadays, a modern ecommerce company may have both online sales and offline sales departments. Normally, online sales attempt to sell in small quantities to individual customers through broad-casting a large amount of emails or promotion codes, which heavily rely on the designed backend algorithms. Offline sales, on the other hand, try to sell in much larger quantities to enterprise customers through contacts initiated by sales representatives, which are more costly compared to online sales. Unlike many previous research works focusing on machine learning algorithms to support online sales, this paper introduces an approach that utilizes heterogenous social networks to improve the effectiveness of offline sales. More specifically, we propose a two-phase framework, HeteroSales , which first constructs a company-to-company graph, a.k.a. Company Homophily Graph (CHG) , from semantics based meta-path learning, and then adopts label propagation on the graph to predict promising companies that we may successfully close an offline deal with. Based on the statistical analysis on the world’s largest professional social network, LinkedIn, we demonstrate interesting discoveries showing that not all the social connections in a heterogeneous social network are useful in this task. In other words, some proper data preprocessing is essential to ensure the effectiveness of offline sales. Finally, through the experiments on LinkedIn social network data and third-party offline sales records, we demonstrate the power of HereroSales to identify potential enterprise customers in offline sales.
</div><br></section><section id="date2017-01-14" ><h3 ><hr>Date:2017-01-14<br></h3><b>Title: </b>Learning Deep Representations of Fine-Grained Visual Descriptions<br><b>Speaker: </b>李甫宪<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/Learning Deep Representations of Fine-Grained Visual Descriptions.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">State-of-the-art methods for zero-shot visual recognition formulate learning as a joint embedding problem of im-ages and side information. In these formulations the current best complement to visual features are attributes: manually-encoded vectors describing shared characteristics among categories. Despite good performance, attributes have lim-itations: (1) finer-grained recognition requires commensu-rately more attributes, and (2) attributes do not provide a natural language interface. We propose to overcome these limitations by training neural language models from scratch; i.e . without pre-training and only consuming words and characters. Our proposed models train end-to-end to align with the fine-grained and category-specific content of images. Natural language provides a flexible and compact way of encoding only the salient visual aspects for distin-guishing categories. By training on raw text, our model can do inference on raw text as well, providing humans a fa-miliar mode both for annotation and retrieval. Our model achieves strong performance on zero-shot text-based image retrieval and significantly outperforms the attribute-based state-of-the-art for zero-shot classification on the Caltech-UCSD Birds 200-2011 dataset.
</div><br><b>Title: </b>Embedding Label Structures for Fine-Grained Feature Representation<br><b>Speaker: </b>方宾伟<br><b>Paper:</b>CVPR2016<a href="http://114.55.145.9:8080/References/seminar/CVPR2016/Embedding Label Structures for Fine-Grained Feature Representation.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">Recent algorithms in convolutional neural networks (CNN) considerably advance the fine-grained image clas-sification, which aims to differentiate subtle differences among subordinate classes. However, previous studies have rarely focused on learning a fined-grained and struc-tured feature representation that is able to locate simi-lar images at different levels of relevance, e.g ., discover-ing cars from the same make or the same model, both of which require high precision. In this paper, we propose two main contributions to tackle this problem. 1) A multi-task learning framework is designed to effectively learn fine-grained feature representations by jointly optimizing both classification and similarity constraints. 2) To model the multi-level relevance, label structures such as hierar-chy or shared attributes are seamlessly embedded into the framework by generalizing the triplet loss. Extensive and thorough experiments have been conducted on three fine-grained datasets, i.e ., the Stanford car, the Car-333, and the food datasets, which contain either hierarchical labels or shared attributes. Our proposed method has achieved very competitive performance, i.e ., among state-of-the-art classification accuracy when not using parts. More im-portantly, it significantly outperforms previous fine-grained feature representations for image retrieval at different levels of relevance.
</div><br><b>Title: </b>Immersive Recommendation News and Event recommendations Using Personal Digital Traces<br><b>Speaker: </b>王金宝<br><b>Paper:</b>WWW2016<a href="http://114.55.145.9:8080/References/seminar/WWW2016/Immersive Recommendation News and Event recommendations Using Personal Digital Traces.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">We propose a new user-centric recommendation model, called Im-mersive Recommendation, that incorporates cross-platform and di-verse personal digital traces into recommendations. Our context-aware topic modeling algorithm systematically profiles users’ in-terests based on their traces from different contexts, and our hybrid recommendation algorithm makes high-quality recommendations by fusing users’ personal profiles, item profiles, and existing rat-ings. Specifically, in this work we target personalized news and lo-cal event recommendations for their utility and societal importance. We evaluated the model with a large-scale offline evaluation lever-aging users’ public Twitter traces. In addition, we conducted a di-rect evaluation of the model’s recommendations in a 33-participant study using Twitter, Facebook and email traces. In the both cases, the proposed model showed significant improvement over the state-of-the-art algorithms, suggesting the value of using this new user-centric recommendation model to improve recommendation qual-ity, including in cold-start situations.
</div><br><b>Title: </b>Point-of-Interest Recommendations Learning Potential Check-ins from Friends<br><b>Speaker: </b>靳继伟<br><b>Paper:</b>KDD2016<a href="http://114.55.145.9:8080/References/seminar/KDD2016/Point-of-Interest Recommendations Learning Potential Check-ins from Friends.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">The emergence of Location-based Social Network (LBSN) services provides a wonderful opportunity to build person-alized Point-of-Interest (POI) recommender systems. Al-though a personalized POI recommender system can sig-ni cantly facilitate users' outdoor activities, it faces many challenging problems, such as the hardness to model user's POI decision making process and the discretizesculty to address data sparsity and user/location cold-start problem. To cope with these challenges, we de ne three types of friends (i.e., social friends, location friends, and neighboring friends) in LBSN, and develop a two-step framework to leverage the information of friends to improve POI recommendation ac-curacy and address cold-start problem. Speci cally, we rst propose to learn a set of potential locations that each indi-vidual's friends have checked-in before and this individual is most interested in. Then we incorporate three types of check-ins (i.e., observed check-ins, potential check-ins and other unobserved check-ins) into matrix factorization model using two di erent loss functions (i.e., the square error based loss and the ranking error based loss). To evaluate the proposed model, we conduct extensive experiments with many state-of-the-art baseline methods and evaluation metrics on two real-world data sets. The experimental results demon-strate the e ectiveness of our methods.
</div><br><b>Title: </b>AntMiner Mining More Bugs by Reducing Noise Interference<br><b>Speaker: </b>朱天潼<br><b>Paper:</b>ICSE2016<a href="http://114.55.145.9:8080/References/seminar/ICSE2016/AntMiner Mining More Bugs by Reducing Noise Interference.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">Detecting bugs with code mining has proven to be an effective approach. However, the existing methods suffer from reporting serious false positives and false negatives. In this paper, we developed an approach called AntMiner to improve the precision of code mining by carefully preprocessing the source code. S pecifically, we employ the program slicing technique to decompose the original source repository into independent sub-repositories , taking critical operations (automatically extracted from source code) as slicing criteria. In this way, the statements irrelevant to a critical operation are excluded from the corr esponding sub-repository. Besides, various semantics-equivalent representations are normalized into a canonical form . E ventually, the mining process can be performed on a refined code database, and false positives and false negatives can be significantly pruned. We have implemented AntMiner a nd a pplied it to detect bugs in the Linux kernel . It reported 52 violations that have been either confirmed as real bugs by the kernel development community or fi xed in new kernel versions. Among them, 41 cannot be dete cted by a widely used representative analysis tool Coverity . Besides, the result of a comparative analysis shows that our approach can effectively improve the precision of code mining and detect subtle bugs that have previously been missed .
</div><br><b>Title: </b>SSD Single Shot MultiBox Detector<br><b>Speaker: </b>肖浩泉<br><b>Paper:</b>ECCV2016<a href="http://114.55.145.9:8080/References/seminar/ECCV2016/SSD Single Shot MultiBox Detector.pdf">[PDF]</a>&nbsp;<a href="http://114.55.145.9:8080/References/seminar/PPT/"></a><br><b>Abstract:<br> </b><div style="text-align:justify">We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of bounding box priors over different aspect ratios and scales per feature map location. At prediction time, the network generates confidences that each prior corresponds to objects of interest and produces adjustments to the prior to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. Our SSD model is simple relative to methods that requires object proposals, such as R-CNN and Multi-Box, because it completely discards the proposal generation step and encapsulates all the computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on ILSVRC DET and PASCAL VOC dataset confirm that SSD has comparable performance with methods that utilize an additional object proposal step and yet is 100-1000×faster. Compared to other single stage methods, SSD has similar or better performance, while providing a unified framework for both training and inference.
</div><br><hr><div id="footer" style="text-align: center">Internal Information &copy 2016 IVSN Group</div></div></body></html>
